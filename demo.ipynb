{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: LLM From Scratch for Chatbot
",
    "This notebook shows how to load the package, download pretrained weights, fine‑tune on Alpaca data, and generate text."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {"execution": {}},
   "source": [
    "# Install dependencies (run once)
",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {"execution": {}},
   "source": [
    "from download import load_gpt2_checkpoint, load_params
",
    "from transformer.model import GPTModel
",
    "# Download GPT-2 small and load
",
    "hparams, params = load_gpt2_checkpoint('gpt2/124M')
",
    "model = GPTModel(hparams)
",
    "load_params(model, params)
",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {"execution": {}},
   "source": [
    "import pandas as pd
",
    "from data.utils import create_dictionary, format_input
",
    "from data.dataset import InstructionDataset, custom_collate
",
    "from torch.utils.data import DataLoader, random_split
",
    "# Load Alpaca training data from HuggingFace parquet
",
    "df = pd.read_parquet('hf://datasets/tatsu-lab/alpaca/data/train-00000-of-00001.parquet')
",
    "data = create_dictionary(df, max_examples=5000)
",
    "dataset = InstructionDataset(data)
",
    "train_size = int(0.8*len(dataset))
",
    "val_size = len(dataset) - train_size
",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])
",
    "train_loader = DataLoader(train_ds, batch_size=8, collate_fn=lambda b: custom_collate(b, device='cpu'))
",
    "val_loader   = DataLoader(val_ds,   batch_size=8, collate_fn=lambda b: custom_collate(b, device='cpu'))
",
    "# Fine‑tune for 1 epoch
",
    "from train import train
",
    "train_losses, val_losses = train(model, train_loader, val_loader, device='cpu', epochs=1, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {"execution": {}},
   "source": [
    "# Plot train vs. validation loss
",
    "import matplotlib.pyplot as plt
",
    "epochs = range(1, len(train_losses)+1)
",
    "plt.figure()
",
    "plt.plot(epochs, train_losses, marker='o', label='Train')
",
    "plt.plot(epochs, val_losses,   marker='x', label='Val')
",
    "plt.xlabel('Epoch')
",
    "plt.ylabel('Loss')
",
    "plt.title('Train vs. Val Loss')
",
    "plt.legend()
",
    "plt.grid(True)
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {"execution": {}},
   "source": [
    "# Generate a sample response
",
    "from infer import generate_text
",
    "sample = data[0]
",
    "prompt = format_input(sample)
",
    "print('Prompt:
', prompt)
",
    "out = generate_text(model, prompt, max_new_tokens=50, top_k=5, temperature=0.7, device='cpu')
",
    "print('
Generated:
', out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {"name": "python", "version": "3.x"}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}